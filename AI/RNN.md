[주의: 배우는 중, 오늘 배운 내용이 어려..운 관계로 학습 목표에 맞춘 나의 작고 귀여운 휘뚜루 마뚜루 이해]

-통계적 언어 모델 (전통적) 
횟수기반 (확률) -> OOV -> Sparsity (희소성)문제  
- So, 어제 배운 [임베딩 벡터]를 써서 Word2vec, fastText같은 유사성을 끼워넣어 줌.

- This is 신경망 언어 모델 -> 희소성 해소  
---> 이 언어 모델에서 사용되는 것
### **---> :순환 신경망 (RNN)** 

### 얘 특 
- Sequential 한 데이터를 처리 
- 순환(Recurrent) : ->은닉-> 입력->은닉 -> 
   (약간 급식실 줄서는데 오늘 요구르트 나와서 계속 애들이 다시 모른척하고 또 줄서는 느낌) 

- 이론적으로는 무한대로 줄을 늘려서 급식을 설수있긴 하지.. (어떤 길이의 sequential 데이터도 이론적으로는 처리 가능) 
- 근데 무조건 한줄 서기임 두줄 세줄 XX (병렬화 불가능) 

- 그리고 얘가 계속 자기가 요구르트를 이미 먹은걸 까먹거나 100개는 먹었다고 착각해 
  (역전파 과정에서 기울기 소실과 폭발로 인한 장기 의존성) 

###  So, 이 기울기를 조절해보자!! (장단기 기억망)--> **LSTM&GRU**
